<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Jeroen Mols</title>
 <link href="http://jeroenmols.com/atom.xml" rel="self"/>
 <link href="http://jeroenmols.com/"/>
 <icon>http://jeroenmols.com/public/favicon.ico</icon>
 <logo>http://jeroenmols.com/img/profile.jpg</logo>
 <updated>2016-06-24T23:36:32+02:00</updated>
 <id>http://jeroenmols.com</id>
 <author>
   <name>Jeroen Mols</name>
 </author>

 
 <entry>
   <title>Droidcon Berlin recap</title>
   <link href="http://jeroenmols.com/blog/2016/06/18/droidconde/"/>
   <updated>2016-06-18T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2016/06/18/droidconde</id>
   <content type="html">Having founded the entire Droidcon franchise in 2009, Droidcon Berlin is a magical conference to be at. Not only do they have an awesome lineup of speakers (including yours truly). But they also organize great after hour events. Further they&amp;#39;re the first conference ever where I didn&amp;#39;t have any Wi-Fi issues (looking at you #io16).

As there were four different tracks, it was obviously not possible to attend every session. But I did notice some general themes and would like to share my personal highlights with you.



Architecture

While Android is maturing as a platform, developers are also professionalizing their applications. Every growing apps mean that testability, maintenance and refactoring is only increasing in importance.

My key takeaways:


MVP is a UI pattern not an architecture
All dependencies should point in one direction
Don&amp;#39;t be dogmatic
Users don&amp;#39;t care about your architecture




IoT



Interest in IoT products is steadily increasing, but as a developer it is still not easy to create IoT apps. Properly handling things like Bluetooth LE keeps on being plagued by device specific issues. And seemingly simple problems like properly handling a user sign in are still extremely complex.

My key takeaways:


When using BT LE, only support API 21 or higher
Handle all bluetooth LE callbacks on separate HandlerThread
Firebase can handle all sign in complexity for you




Designing for the next billion



Where we used to be educated that &amp;quot;a developer phone is not a user phone&amp;quot;, this message is now morphing towards people in emerging markets. Designing for such markets doesn&amp;#39;t only require functional changes like developing for offline first, but it even requires you to completely think your UX.

My key takeaways:


access to cheap fast internet is not a given
battery life is even more precious in emerging countries
understandable UX when smartphone is your first computer




Other hot topics



Besides these, also a lot of attention was spent on testing and tooling. There were great talks about styling, theming and creating custom views. And many sessions also dived deeper into optimizing your apps performance. Bit unfortunate that there weren&amp;#39;t any more talks on the new Android N features.

My key takeaways:


You can use alpha values for button states in XML
Use overlay themes instead of changing text colors
Tests should be fast, focussed and reliable
It maybe worth to convert an existing app to RXJava, but keep it contained to particular layers. (e.g. Webservice)




Sketchnoting



Sketch notes are really awesome! In this, creative people summarize a talk into a very cool one pager. This doesn&amp;#39;t only look great, but it&amp;#39;s also by far the easiest way to get a high level view of a talk.

At Droidcon both Corey Leigh Latislaw and Teresa Holfeld were actively creating sketch notes. You should check their twitter feeds for the awesome content they created.

Just a sample:

Offline First by @glynn_bird at #droidconDe. #sketchnote pic.twitter.com/SkeriMsigT&amp;mdash; Corey Leigh Latislaw (@corey_latislaw) June 16, 2016


Themes and Styles demystified: talk by @chrisbanes #droidconDE #sketchnotes pic.twitter.com/mXNcW8lGRS&amp;mdash; Teresa Holfeld (@TeresaHolfeld) June 16, 2016


Thanks for both of them for creating such great summaries.



Conference slides

While the conference organizers will publish all slides very soon, I can image that quite a few people are already looking for a sneak preview. Hence I bundled everything I could already gather from socials.


Testing made sweet with a Mockito by Jeroen Mols
Reverse engineering is not just for hackers by Jon Reeve
Refactoring Plaid - A reactive MVP approach by Hannes Dorfmann
Android &amp;amp; IoT by Selim Salman
Unit testing without Robolectric by
Danny Preussler
#Perfmatters for Android by Hasan Hosgel
Life of Android Enterprise Developers in the age of Android for Work by Pietro Maggi
The 2016 Android Developer Toolbox by Gautier Mechling
Practical Bluetooth Low Energy on Android by Erik Hellman
Contextual Communications And Why You Should Care by Marcos Placona
Deep dive into Android Data Binding by Radek Piekarz
Let&amp;#39;s get physical by Albrecht Noll and Pascal Welsch
Testing Why? When? How? by Tomasz Pola≈Ñski
Adopting RxJava on Airbnb Android by Felipe Lima
Elegant?? Unit Testing by Pablo Guardiola
Material design custom views by Said Tahsin Dane
Android TV: Building apps with Google&amp;#39;s Leanback Library by Joe Birch
Screenshot your Entire App by Edward Dale
Little helpers for Android development with Kotlin by Kai Koenig
Effective Android Development by Sergii Zhuk
Android is the World Phone by Corey Latislaw
Loving lean layouts by Huyen Tue Dao
Let it flow - unidirectional data flow architecture on Android by Benjamin Augustin
We&amp;#39;re all UX! by Lydia Selimalhigazi and Caroline Smith
10 ways to analyse runtime failure using Classy Shark by Boris Farber




Credits

Thanks to the entire Droidcon Berlin team for organizing such a great conference and to all sponsers for their support. Keep up the awesome job!
</content>
 </entry>
 
 <entry>
   <title>Efficiently reducing your method count</title>
   <link href="http://jeroenmols.com/blog/2016/05/06/methodcount/"/>
   <updated>2016-05-06T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2016/05/06/methodcount</id>
   <content type="html">As green field projects are a rare breed, chances are that you&amp;#39;ve inherited a legacy code base. If you&amp;#39;re as lucky as me, that code base has over 65k methods causing the build times to be boringly slow.

Today I would like to show how you can visualize your current method count and understand what libraries are eating up the largest part of that. Next it&amp;#39;s time to reduce said method count and remove that nasty multidex solution once and for all.



Visualizing method count

The easiest and most attractive way (imho) to visualize the method count is by using the Dexcount Gradle Plugin. Applying it to your project is as easy as adding a classpath dependency to your root build.gradle and applying the plugin to your App build.gradle.
// root build.gradle file
buildscript {
    repositories {
        jcenter() // or mavenCentral()
    }

    dependencies {
        classpath &amp;#39;com.getkeepsafe.dexcount:dexcount-gradle-plugin:0.5.0&amp;#39;
    }
}
// app build.gradle file (apply AFTER Android plugin)
apply plugin: &amp;#39;com.getkeepsafe.dexcount&amp;#39;

Running a normal project build ./gradlew assembleDebug will now print out the current method count in the console:



and generate an interactive graphical report in the outputs folder build/outputs/dexcount/debugChart:



Click the graphic above to interact with it.

Using the graphical representation of the method count for all packages in your app, it becomes really easy to find which libraries are consuming your precious method count. Some of the usual suspects are big monolithic libraries like Guava and the non-split-up Google play services. In the next section will see what we can do about these.



Reducing method count

Choosing the right libraries

Normally I recommend never to optimize unless you have a problem. But with method counts, I really advice you to consider the method count before you start using a library for two reasons:


Replacing libraries in existing apps can be very challenging, if not almost impossible.
Many developers are using huge libraries just to do simple things. (Strings.isNullOrEmpty() anyone?) Note that you don&amp;#39;t need to use a library for everything!


Fortunately there is a great website methodscount.com that tells you the method count of a library before you start using it. This can really be helpful to avoid using &amp;quot;large libraries&amp;quot; which only add limited benefit to your app.

Replacing existing libraries

Often there are multiple libraries accomplishing the same goals. Take for instance image loading:



Library
Method count



Picasso 2.5.2
849


Universal Image Loader 1.9.5
1206


Glide 3.7.0
2879


Fresco 0.9.0
12984



Each of these libraries have their own benefits and features, so choose wisely and balance the features you are going to use versus the method count impact it will have.

That being said, replacing libraries in existing projects can be incredibly hard and may not even be feasible on the short term. Later I&amp;#39;ll suggest an alternative solution to reduce method count in existing libraries.

Running Proguard

Proguard is a great tool to strip out unused code from your app, but you typically only run it for release builds to save precious build time. If that&amp;#39;s not really an issue for you, by all means you can also enable Proguard for debug builds:
buildTypes {
    debug {
        minifyEnabled true
        proguardFiles getDefaultProguardFile(&amp;#39;proguard-android.txt&amp;#39;), &amp;#39;proguard-rules.pro&amp;#39;
    }
}

Reducing library size

If it&amp;#39;s not feasible to replace an existing library or to run Proguard all the time, then it becomes really interesting. Because if Proguard can strip out code during a release build, why not use it ahead of time to create a modified version of a library with fewer methods?

Well this is possible, but you&amp;#39;ll have to manually specify which parts of the library you are going to use! This is because Proguard doesn&amp;#39;t have a context during library stripping of what methods your application will be needing and what not.

Let&amp;#39;s reproduce one of the projects I recently started working on as an example. Guava was used throughout the app extensively, making it very hard/risky to remove. But because of the huge method count we were constantly flirting with the 65k method limit and had to enable multidex.



First of all you need to know what parts of the library the app was actually using. This can easily be done by running the following command in your src folder.
grep -roh . -e &amp;#39;com.google.common.*&amp;#39; | sort | uniq

This simply looks for all import statements starting with the library prefix (for Guava that is com.google.common), removes all clutter from the grep output, sorts it and takes all unique references.



Next we&amp;#39;ll create a simple Proguard configuration that keeps all top level packages, without any obfuscation or optimizations.
-dontoptimize
-dontobfuscate

-keep public class com.google.common.base.** {
    public *;
}

-keep public class com.google.common.collect.** {
    public *;
}

-keep public class com.google.common.primitives.** {
    public *;
}

-keep public class com.google.common.util.** {
    public *;
}

Now we&amp;#39;ll use a little Gradle script that takes a library as an input, runs Proguard on it an creates a new library as an output. If you&amp;#39;re interested I advice you look at the source code, which is based on a script by @mr_ligi. This Gradle script outputs a shrinked library version, which can be copied to the libs folder of your project.

Looking at our example, this simple process saved us 4000 methods and we are only just above the dex method limit.



Back to the drawing board, because this isn&amp;#39;t nearly enough! Turns out the collect package by itself has over 8000 methods, so I decided to just keep certain classes instead of the entire package.

This more aggressive approach will most likely cause some compile errors when you try to use the library in your app, so I had to iterate and add some extra classes until all of those were solved. The resulting Proguard configuration looks like this:
-dontoptimize
-dontobfuscate

-keep public class com.google.common.base.** {
    public *;
}

-keep public class com.google.common.collect.Sets
-keepclassmembers class com.google.common.collect.Sets** {
 *;
 }

 -keep public class com.google.common.collect.Collections2
 -keepclassmembers class com.google.common.collect.Collections2** {
  *;
  }

-keep public final class com.google.common.collect.Lists
-keepclassmembers class com.google.common.collect.Lists** {
 *;
 }

-keep public final class com.google.common.collect.Iterables
-keepclassmembers class com.google.common.collect.Iterables** {
 *;
 }

-keep public class com.google.common.collect.ImmutableList.** {
    public *;
}

-keep public class com.google.common.io.CharStreams {
    public *;
}

-keep public class com.google.common.collect.HashMultiset
-keepclassmembers class com.google.common.collect.HashMultiset** {
 *;
 }

-keep public class com.google.common.collect.HashBiMap
-keepclassmembers class com.google.common.collect.HashBiMap** {
 *;
 }

-keep public class javax.annotation.Nullable.** {
     public *;
 }

-keep public class com.google.common.util.** {
    public *;
}

-keep public class com.google.common.primitives.** {
    public *;
}

Resulting in an extra decrease of almost 4500 methods, which brings the total removed methods to 8500!



Further our build times have not only improved because we no longer need multidexing, but also because the compiler now has less code to process.

Obviously your mileage will vary depending on what library you choose. For low coupled, highly cohesive libraries (like Guava), this technique works really well, but for other libraries it might not.


Disclaimer

The technique presented above should be used with caution! Because instead of relying on Proguard to strip out what&amp;#39;s not needed, we&amp;#39;re now doing that manually, which is more error prone.




Wrap-up

Hitting the 65k method limit is a real pain, but choosing wisely what libraries you use can already bring you a long way. Fortunately there are great tools like the Dexcount Gradle Plugin and methodscount.com to help with these decisions.

For existing projects, always try to replace existing large method libraries with alternatives. If this is not feasible and you feel comfortably using Proguard, you can use the latter to preprocess and shrink existing libraries.

A basic example project with everything in this blogpost integrated is available on GitHub.

As always you can reach me @molsjeroen on twitter, or leave a comment below!
</content>
 </entry>
 
 <entry>
   <title>Droidcon Italy recap</title>
   <link href="http://jeroenmols.com/blog/2016/04/08/droidconit/"/>
   <updated>2016-04-08T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2016/04/08/droidconit</id>
   <content type="html">A conference about our favorite Green little robots? In sunny Italy? With great food and a party? Yeah, I can image how you must feel in case you missed it... I on the other hand was fortunate enough to attend and speak at this awesome conference.

With over 770 attendees and four different tracks, it was obviously not possible to attend every session. But I did notice some general themes and would like to share my personal highlights with you.



We are all UX



The holy grail in app development is to have an amazing user experience. While app performance and feature set are obviously important, you must also understand your users, simplify main use cases and have a delightful design.

Do you really think a developer or designer alone can create such a great UX? NO, off course not! They&amp;#39;ll both have to work together and synergize to really blow the users of their feet. We need more pairing between developers and designers folks!

The best advice I got was:


A prototype is worth a thousand meetings.
Five people to test your prototype with is the sweet spot. It&amp;#39;s enough to notice patterns, yet not too much to be a burden.
Developers and designers should be transparent and open to learn from each other
&amp;quot;How might we...&amp;quot; is a great way to phrase problems as opportunities




Optimizing layouts



Screens containing a lot of views can sometimes render slowly. Mostly caused by deeply nested view hierarchies and/or using RelativeLayouts as a root element. Using &amp;quot;heavy&amp;quot; layouts in lists or increased nesting makes these problems multiplicative instead of simply additive.

When running into issues, first resolve to Lint and investigate all warnings. If the problem persist, Hierarchy viewer will help you understanding what&amp;#39;s going on. Always prefer simple solutions over complex ones and if you really really have to you can go - Facebook Style - replacing views with drawables.

The best advice in this track was:


Rendering times in Hierarchy Viewer are not reliable
Optimize responsibly




DEX diet



Hitting the DEX method limit or trying to improve your app security? As a real Proguard expert you created an amazing configuration and now all those problems are gone. Or are they?

Analyzing your own APK file is a must to verify what methods are actually stripped and what code is obfuscated. Who knows you might even find some duplicate dependencies (GSON anyone?), causing a further method count reduction. Thanksfully all of this has become a breeze thanks to tools like ClassyShark.

The best advice here was:


Be restrictive using Proguard iso keeping entire packages
IDE method count != dex method count
Use methodscount.com to see how large a lib is before using it




Other hot topics



Besides the three main themes, other topics varied from Kotlin, over library distribution to (MVP) architecture and app store optimizations. Awesome sources of inspiration, brought by even more awesome speakers.

My key takeaways:


Use App invites to grow your user base
If you don&amp;#39;t like testing your code, most likely customers won&amp;#39;t like testing your app either
Italian food is awesome




Conference slides


Distribute your libraries via Maven, even privately by Jeroen Mols
Think like a designer by Nick Butcher
Let it flow by Benjamin Augustin
#Perfmatters for Android by Hasan Hosgel
Android Library A-Z by Martin Liersch
The bytecode mumbo-jumbo by Raimon R√†fols
To ‚àû (~65K) and beyond! by Sebastiano Gottardo
Android data binding in action using MVVM pattern by Fabio Collini
From Clockwork to smartwatch by Daniele Bonaldo
Android internal library management by Kelly Shuster
Reverse engineering is not just for hackers by Jon Reeve
How to talk to your users by Alex Florescu
Crafting Great Hypotheses by Hoang Huynh
Building maintainable app with MVP and Dagger2 by Kristijan Jurkoviƒá
Build An Efficient REST Client On Android by Matteo Gazzurelli
Chronicles of TDD by Luca Falsina
Backend 4 Android developers by
Antonio Mallia &amp;amp; Nicola Corti
A realtime infrastructure for Android apps: Firebase may be what you need..and even more! by
Alessandro Martellucci
Evolving the Android core with Aspects by Carlo Pescio
Android: It&amp;#39;s time to go to work! by Pietro Maggi
Drive together not the same by Giovanni Laquidara
A friend in need - A JS indeed by Yonatan Levin
Application Architecture for Scaled Agile by Sangsoo Nam
FLUX based clean architecure by Luca Bruzzone
Engage and retain users in android world by Matteo Bonifazi
Bonjour Android, it&amp;#39;s Zeroconf by Roberto Orgiu
We&amp;#39;re all UX! by Lydia Selimalhigazi and Caroline Smith
Mastering the NDK by Xavier Hallade
BLE beacons, Eddystone and Physical Web by Alessio Cucini and Samuele Forconi
World-Class Testing Development Pipeline for Android by Pedro Vicente G√≥mez S√°nchez]
ClassShark - Android and Java executables browser by Boris Farber




Credits

Thanks to the entire Droidcon Italy team for organizing such a great conference and to all sponsers for their support.


</content>
 </entry>
 
 <entry>
   <title>A successful XML naming convention</title>
   <link href="http://jeroenmols.com/blog/2016/03/07/resourcenaming/"/>
   <updated>2016-03-07T00:00:00+01:00</updated>
   <id>http://jeroenmols.com/blog/2016/03/07/resourcenaming</id>
   <content type="html">Do you remember the last time you had to dig into strings.xml to find the right String to use? Or that you manually had to go over all drawables to find the one you needed?

Whenever we start a new project, we take a lot of care in setting up our architecture, CI, build flavors,... But do you also have a strategy to name your resources?

You should! Because the lack of XML namespaces, makes managing Android resources tedious. And causes things to grow out of control easily, especially in large projects.

So let&amp;#39;s introduce a simple scheme that will solve your pains.


easy lookup of any resource (autocomplete)
logical, predictable names
clean ordering of resources
strongly typed resources


This blogpost will explain the mechanism, its advantages, limitations and provide an easy to use cheat sheet.



Basic principle

All resource names follow a simple convention.



Let&amp;#39;s first describe every element briefly. After the advantages, we&amp;#39;ll see how this applies to each resource type.

&amp;lt;WHAT&amp;gt;

Indicate what the resource actually represents, often a standard Android view class. Limited options per resource type.  (e.g. MainActivity -&amp;gt; activity)

&amp;lt;WHERE&amp;gt;

Describe where it logically belongs in the app. Resources used in multiple screens use all, all others use the custom part of the Android view subclass they are in.  (e.g. MainActivity -&amp;gt; main, ArticleDetailFragment -&amp;gt; articledetail)

&amp;lt;DESCRIPTION&amp;gt;

Differentiate multiple elements in one screen.  (e.g. title)

&amp;lt;SIZE&amp;gt; (optional)

Either a precise size or size bucket. Optionally used for drawables and dimensions.   (e.g. 24dp, small))



Download and print the cheat sheet for easy reference.


Advantages


Ordering of resources by screen 
The WHERE part describes what screen a resource belongs to. Hence it is easy to get all IDs, drawables, dimensions,... for a particular screen.
Strongly typed resource IDs 
For resource IDs, the WHAT describes the class name of the xml element it belongs to. This makes is easy to what to cast your findViewById() calls to.
Better resource organizing 
File browsers/project navigator usually sort files alphabetically. This means layouts and drawables are grouped by their WHAT (activity, fragment,..) and WHERE prefix respectively. A simple Android Studio plugin/feature can now display these resources as if they were in their own folder.
More efficient autocomplete 
Because resource names are far more predictable, using the IDE&amp;#39;s autocomplete becomes even easier. Usually entering the WHAT or WHERE is sufficient to narrow autocomplete down to a limited set of options.
No more name conflicts 
Similar resources in different screens are either all or have a different WHERE. A fixed naming scheme avoids all naming collisions.
Cleaner resource names 
Overall all resources will be named more logical, causing a cleaner Android project.
Tools support 
This naming scheme could be easily supported by the Android Studio offering features such as: lint rules to enforce these names, refactoring support when you change a WHAT or WHERE, better resource visualisation in project view,...




Layouts

Layouts are relatively simple, as there usually are only a few layouts per screen. Therefore the rule can be simplified to:



Where &amp;lt;WHAT&amp;gt; is one of the following:



Prefix
Usage



activity
contentview for activity


fragment
view for a fragment


view
inflated by a custom view


item
layout used in list/recycler/gridview


layout
layout reused using the include tag



Examples:


activity_main: content view of the MainActivity
fragment_articledetail: view for the ArticleDetailFragment
view_menu: layout inflated by custom view class MenuView
item_article: list item in ArticleRecyclerView
layout_actionbar_backbutton: layout for an actionbar with a backbutton (too simple to be a customview)




Strings

The &amp;lt;WHAT&amp;gt; part for Strings is irrelevant. So either we use &amp;lt;WHERE&amp;gt; to indicate where the string will be used:



or all if the string is reused throughout the app:



Examples:


articledetail_title: title of ArticleDetailFragment
feedback_explanation: feedback explanation in FeedbackFragment
feedback_namehint: hint of name field in FeedbackFragment
all_done: generic &amp;quot;done&amp;quot; string


&amp;lt;WHERE&amp;gt; obviously is the same for all resources in the same view.



Drawables

The &amp;lt;WHAT&amp;gt; part for Drawables is irrelevant. So either we use &amp;lt;WHERE&amp;gt; to indicate where the drawable will be used:



or all if the drawable is reused throughout the app:



Optionally you can add a &amp;lt;SIZE&amp;gt; argument, which can be an actual size &amp;quot;24dp&amp;quot; or a size qualifier &amp;quot;small&amp;quot;.

Examples:


articledetail_placeholder: placeholder in ArticleDetailFragment
all_infoicon: generic info icon
all_infoicon_large: large version of generic info icon
all_infoicon_24dp: 24dp version of generic info icon




IDs

For IDs, &amp;lt;WHAT&amp;gt; is the class name of the xml element it belongs to. Next is the screen the ID is in, followed by an optional description to distinguish similar elements in one screen.



Examples:


tablayout_main -&amp;gt; TabLayout in MainActivity
imageview_menu_profile -&amp;gt; profile image in custom MenuView
textview_articledetail_title -&amp;gt; title TextView in ArticleDetailFragment




Dimensions

Apps should only define a limited set of dimensions, which are constantly reused. This makes most dimensions all by default.

Therefore you should mostly use:



and optionally use the screen specific variant:



Where &amp;lt;WHAT&amp;gt; is one of the following:



Prefix
Usage



width
width in dp


height
height in dp


size
if width == height


margin
margin in dp


padding
padding in dp


elevation
elevation in dp


keyline
absolute keyline measured from view edge in dp


textsize
size of text in sp



Note that this list only contains the most used &amp;lt;WHAT&amp;gt;s. Other dimensions qualifiers like: rotation, scale,... are usually only used in drawables and as such less reused.

Examples:


height_toolbar: height of all toolbars
keyline_listtext: listitem text is aligned at this keyline
textsize_medium: medium size of all text
size_menu_icon: size of icons in menu
height_menu_profileimage: height of profile image in menu




Known limitations


Screens need to have unique names
To avoid collisions in the &amp;lt;WHERE&amp;gt; argument, View (like) classes must have unique names. Therefore you cannot have a &amp;quot;MainActivity&amp;quot; and a &amp;quot;MainFragment&amp;quot;, because the &amp;quot;Main&amp;quot; prefix would no longer uniquely identify one &amp;lt;WHERE&amp;gt;.
Refactoring not supported
Changing class names does not change along resource names when refactoring. So if you rename &amp;quot;MainActivity&amp;quot; to &amp;quot;ContentActivity&amp;quot;, the layout &amp;quot;activity_main&amp;quot; won&amp;#39;t be renamed to &amp;quot;activity_content&amp;quot;. Hopefully Android Studio will one day add support for this.
Not all resource types supported
The proposed scheme currently does not yet support all resource types. For some resources this is because they are less frequently used and tend to be very varied (e.g. raw and assets). For other resources this is because they are a lot harder to generalize (e.g. themes/styles/colors/animations).

Your apps colors palette likely wants to reuse the terminology of your design philosophy. Animations can range from modest (fade) to very exotic. Themes and styles already have a naming scheme that allows you to implicitly inherit properties.




Wrap-up

That&amp;#39;s it! A clean simple and easy to use resource naming scheme. Don&amp;#39;t forget to download the cheat sheet for easy reference!

Even though this scheme doesn&amp;#39;t (yet) cover all resource types, it does provide an easy to use solution for where most naming pain currently is. In a future blogpost I&amp;#39;ll also make a suggestion for the other ones.

Let me know what you think by contacting me @molsjeroen on twitter, or leaving a comment below!
</content>
 </entry>
 
 <entry>
   <title>Git as a secure private Maven repository</title>
   <link href="http://jeroenmols.com/blog/2016/02/05/wagongit/"/>
   <updated>2016-02-05T00:00:00+01:00</updated>
   <id>http://jeroenmols.com/blog/2016/02/05/wagongit</id>
   <content type="html">As my previous blogposts already covered how to set up a private Maven repository, you might wonder &amp;quot;Why again a Maven blogpost?&amp;quot;. Well that&amp;#39;s a fair question and the answer is twofold:


Backup mechanism, to ensure you never ever loose releases.
Remote access outside of your local network (intranet).


And Git implicitly solves both! :)

I&amp;#39;ll demonstrate how to configure Bitbucket as a free private remote Maven repository and automate everything in one simple Gradle script.

Preface

While you could use any Git repository (like GitHub), I choose Bitbucket as it offers free private repositories for small teams. Furthermore it has an API which we will need for some of the wizardry later on.

All source code is available on Github and can be used after some minor BitBucket configuration. You can find the Gradle script in a separate repository.

Bitbucket

Without any further a do, lets get to it and start configuring BitBucket.

Login to Bitbucket and create a new private repository called maven_repository.



Checkout the repository locally, create a README.md file and commit that file to your local branch. Now push that branch to BitBucket, BUT make sure to push it to a remote branch called &amp;quot;releases&amp;quot;. (this is key, as the plugin we&amp;#39;ll use later on depends on this)




Troubleshooting releases branch
If you accidentally push your local branch to a remote called master, create a new branch locally called releases, push that to a remote releases and change your main branch in the BitBucket settings for that repository.



You can safely remove origin/master if you want.


Wagon-git

To upload Maven artifacts to a Git repository, we will use a Maven plugin called Wagon-git, which can hook into the existing Gradle DSL for Maven uploads.

Simply add a new repository:
repositories {
    maven { url &amp;quot;https://raw.github.com/synergian/wagon-git/releases&amp;quot; }
}

And configure Maven like you would normally do, but with our BitBucket repository url in a particular format:
uploadArchives {
    repositories.mavenDeployer {
        ...
        repository(url: &amp;#39;git:releases://git@bitbucket.org:&amp;#39; + COMPANY + &amp;#39;/&amp;#39; + REPOSITORY_NAME + &amp;#39;.git&amp;#39;)
        ...
    }
}

Where COMPANY is the name of your BitBucket organization and REPOSITORY_NAME is maven_repository.

Now you can simply create a new release by running the following command:
./gradlew assembleRelease uploadArchives

And check BitBucket for the resulting artifacts.





Unique versions only

As Git naturally allows you to override existing files, we will need to do something to prevent this from happening. Otherwise, you could have a v1.1.3 library, which is stable one day and full of bugs the next (because someone replaced it in the Maven repo). Not exactly what you want, right?

We will use the BitBucket API to verify if a particular release already exists:
task lookForArtifacts {
    doLast {
        ...
        def repositoryUrl = &amp;#39;https://api.bitbucket.org/1.0/repositories/&amp;#39; + COMPANY + &amp;#39;/&amp;#39; + REPOSITORY_NAME + &amp;#39;/raw/releases/&amp;#39; + artifactPath
        ...
        if (urlExists(repositoryUrl)) {
            throw new RuntimeException(&amp;quot;Artifact with version &amp;quot; + ARTIFACT_VERSION + &amp;quot; already exist - not executing uploadArchives&amp;quot;)
        }
        return true
    }
}

Quite simple actually: just reverse engineer the url of a particular release artifact and the see if we get a 200 response or not.

Finally we ensure that we always run the previous task before running the Maven task:
uploadArchives.dependsOn lookForArtifacts

Running ./gradlew uploadArchives now successfully creates a release.



Consuming artifacts

Add your Maven repository to the list of repositories in your main build.gradle file:
allprojects {
    repositories {
        jcenter()

        maven {
            credentials {
                username USERNAME
                password PASSWORD
            }
            url &amp;quot;https://api.bitbucket.org/1.0/repositories/jeroenmols/maven_repository/raw/releases&amp;quot;
        }
    }
}

Note that we have to provide a username and password as we are connecting to a private repository.


Important

Make sure not to put your username and password directly into the build.gradle file! That would be a major security risk. Instead have a look at this blogpost to learn how to securely provide a username and password.


Now simply add a dependency on your library like you are used to and you&amp;#39;re ready.
dependencies {
    ...
    compile &amp;#39;com.jeroenmols.awesomelibrary:awesomelibrary:1.0.0&amp;#39;
}

Putting it all together

To make your life a lot easier, I&amp;#39;ve created a Gradle script that does everything for you.

Setting up your project is easy:


Add the following plugin to the top of the build.gradle file in your library folder

  apply from: &amp;#39;https://raw.githubusercontent.com/JeroenMols/GitAsMaven/master/publish-bitbucket.gradle&amp;#39;


Create a gradle.properties file within your library folder with the following parameters:

  ARTIFACT_VERSION=&amp;lt;version_here&amp;gt;
  ARTIFACT_NAME=&amp;lt;libraryname_here&amp;gt;
  ARTIFACT_PACKAGE=&amp;lt;packagename_here&amp;gt;
  ARTIFACT_PACKAGING=aar //You could also use jar

  COMPANY=&amp;lt;bitbucket_team_company_here&amp;gt; //Username if not part of team
  REPOSITORY_NAME=&amp;lt;bitbucket_reponame_here&amp;gt;


Create a gradle.properties file in the root of your project (or better in the global .gradle folder on your system) with the following parameters

  USERNAME=&amp;lt;username_here&amp;gt;
  PASSWORD=&amp;lt;password_here&amp;gt;


Run the following command to upload a version to your Maven repository.

  ./gradlew uploadArchives

Thats&amp;#39;s it!

Wrap-up

Configuring BitBucket or GitHub as a (private) Maven repository is quite easy and can be fully automated in a single Gradle script. Hopefully this blogpost has inspired many of you to start reusing more code.

A basic example project with everything in this blogpost integrated is available on GitHub. Or you can also directly integrate the Gradle script into your library.

As always you can reach me @molsjeroen on twitter, or leave a comment below!
</content>
 </entry>
 
 <entry>
   <title>Year in review 2015</title>
   <link href="http://jeroenmols.com/blog/2016/01/29/yearinreview/"/>
   <updated>2016-01-29T00:00:00+01:00</updated>
   <id>http://jeroenmols.com/blog/2016/01/29/yearinreview</id>
   <content type="html">Finally found the time to write my year in review. #insomnia

2015 was a huge year for me! I even dare to say the biggest one of my life so far as I became a father of a lovely daughter Lene. Its really hard to over state how big of an impact that has on your life and how fantastic it is to see your own baby grow (and recognize parts of yourself in her). This obviously also explains my late year in review post. #perfectexcuse

On a technical level I also fared well and I&amp;#39;m very happy with what I&amp;#39;ve been able to accomplish:


Created an library with &amp;gt;500 stars on  Github
Started my own blog and website
Featured blogpost in Android Weekly
Spoke at my first conference Droidcon Paris
Actively started using twitter and gained &amp;gt;100 followers
Gained &amp;gt;1000 reputation on stackoverflow
Landed a new job at Philips Hue
Learned Xamarin and built a cross platform app
Wrote the worlds latest year in review post


Next year will be more challenging as my daughter has become a lot more effective at grabbing my attention than my laptop. However I want to increase my efforts contributing back to the community by speaking at more conferences and writing more blogposts. Finally I also want to visit Google IO, which is about time I got there, don&amp;#39;t you agree? ;)

As always you can reach me @molsjeroen on twitter, or leave a comment below!
</content>
 </entry>
 
 <entry>
   <title>Level up GitHub builds with CI and code coverage</title>
   <link href="http://jeroenmols.com/blog/2015/11/13/traviscoveralls/"/>
   <updated>2015-11-13T00:00:00+01:00</updated>
   <id>http://jeroenmols.com/blog/2015/11/13/traviscoveralls</id>
   <content type="html">Wouldn&amp;#39;t you love to have your open source projects built automatically by a continuous integration server? And to have a detailed code coverage report for all your unit tests? Even when someone generated a pull request? And how about having cool badges to show off all of this?

 

Actually, all of this a breeze to set up, once you understand what works and what doesn&amp;#39;t. It is even completely free for open source projects!

In less than half an hour, this blogpost will add CI and code coverage to your projects, just like I did for my own library LandscapeVideoCamera. While this article focusses on Android, the material presented here can quite easily be extended to a broader scope.

Preface

In order to keep things simple, I created a very basic project containing a Calculator class and some Android tests. This will make things easier to understand as we&amp;#39;ll add everything step by step to this project.

Later on I will present a more elaborate (and usefull) example, namely my own open source library LandscapeVideoCamera. Some time ago, I test driven refactored this project completely resulting in respectable code coverage statistics.

Travis

About

Travis is a feature rich online CI service which integrates nicely with a lot of existing services. One major advantage over Jenkins is that you can put the entire CI configuration file under version control. It is completely free for open source projects, although private repositories are also supported on a subscription basis.



Basic configuration

In order to get started, go to travis-ci.org, login with your GitHub account and authorize Travis to access your repositories.



Next, create a new file .travis.yml into the root of your project (note that this file will be hidden on Mac OSX/Linux systems). Open the file and specify the language of your project, in our case Android:
language: android

Now Travis needs to know all dependencies in order to build the project. As such specify the build tools version and compile Android SDK version (note that this must match the compileSdkVersion of your build.gradle file!). While there is an option to use the latest build tools version, I recommend to declare an explicit version as this makes your builds more reproducible. Next specify all of the Android SDK manager dependencies your project needs so Travis can install them before building the project.
android:
  components:
    - build-tools-22.0.1
    - android-23
    - extra-android-m2repository

Note that our sample only depends on the AppCompat and design support library, hence there is only one extra defined extra-android-m2repository. In case your project uses other dependencies from the Android SDK, you can easily select them from the entire dependency list and add an extra item.


Extra: listing Android SDK dependencies

To generate the above mentioned list of Android SDK components, simply run the following command on your local machine:
android list sdk --no-ui --all --extended


After, specify the exact Gradle command to run, in our case assembleDebug:
script:
    - ./gradlew assembleDebug

Now that we have configured everything in the travis.yml file, we need to enable the project, so Travis will start listening to code changes. This can be done by going to your profile on Travis and flipping the appropriate slider.



This will result in the project being shown on the left hand side of your dashboard, while indicating that there are no builds.



Builds are automatically triggered whenever you push code to your GitHub repository or someone else creates a pull request. Therefore push some changes to GitHub and watch Travis pick them up automatically and start building your project.



Congrats! You now have a fully working Continuous Integration server for your open source project.

Running Android unit tests

While running normal unit tests is straight forward, Android tests are a different story because they require an Android emulator to run on. And because Travis support for Android is still in beta, there are a couple of limitations to consider:


Only armeabi-v7a emulators are supported.
The Android M emulator is not yet supported.



Extra limitations of Travis Android support

You can skip this if you want, just some extra context

First of all, Travis does not yet support HAXM to speed up intel emulators, so there is no speed up while using an x86 emulator. Even more, the latest x86_64 Android M emulator requires hardware acceleration, so that one simply cannot be used on Travis! For more information see issue 1419 and 1395 or check out this failing build.

Secondly, Travis does not yet support the latest Android M emulator, causing the built-in android-wait-for-emulator script to time out while the emulator is booting. Therefore I recommend to use the android-22 emulator instead. For more information see this failing build.


So you&amp;#39;ll have to accept that builds will be slow (starting emulator + running test) and that you cannot use an Android M emulator. But if these are acceptable, read on and I&amp;#39;ll explain how to set up everything for running tests.

First of all, define the Android version and processor architecture of the emulator by adding a new environment at the top of the travis.yml file:
env:
  matrix:
    - ANDROID_TARGET=android-22 ANDROID_ABI=armeabi-v7a

Then, ensure that all dependencies for the Android emulator are installed, by adding both the platform version and emulator image to the components section. Note that it is important to add both, because the Android emulator will only install if the corresponding Android platform is installed (see this failing build).
android:
  components:
    ...
    - android-22
    - sys-img-armeabi-v7a-android-22

Now we need to create a new Android emulator and start it before our build. As starting takes a really long time, Travis offers a built-in android-wait-for-emulator script to facilitate this. Finally we need to unlock the emulator once started by sending a key event.
before_script:
    - echo no | android create avd --force -n test -t $ANDROID_TARGET --abi $ANDROID_ABI
    - emulator -avd test -no-skin -no-audio -no-window &amp;amp;
    - android-wait-for-emulator
    - adb shell input keyevent 82 &amp;amp;

After all of this configuration, all we need to do is change the Gradle command to run all of the tests and trigger a new build by pushing all these changes.
script:
    - ./gradlew connectedAndroidTest

Taking things further

As mentioned in the introduction, Travis is a really feature rich CI service. Therefore this section provides some tips to take things even further.


Build notifications: Travis supports sending notifications via Slack, HipChat, email,... whenever a built fails/succeeds.
For more information, have a look at the Travis documentation.

notifications:
    email:
      - your.email@gmail.com


Build status badge: Click the build badge on your Travis homepage to generate png/markdown/... build badges.

Branch information: Print which branch or pull request is being built.

script:
    - echo &amp;quot;Travis branch is $TRAVIS_BRANCH&amp;quot;
    - echo &amp;quot;Travis branch is in pull request $TRAVIS_PULL+REQUEST&amp;quot;


More options: Have a look at the Travis documentation.


Coveralls

About

Coveralls is a visually attractive online code coverage tool which provides detailed statistics such as line coverage and repository trends. Furthermore it allows you to show of your code coverage and encourages you to increase it. Like Travis, it is free for open source projects, but a subscription service is available for private repositories.



Enabling Android code coverage

First of all, your Android project needs to be configured to generate code coverage reports. As such, ensure that you are using at least version 0.4 of the Android testing support library (there was an issue in version 0.3).

Then add the flag testCoverageEnabled to the debug buildTypes in your main module&amp;#39;s build.gradle file, causing a code coverage report to be generated in the build/reports/coverage/ folder.
android {
  ...

  buildTypes {
        debug {
            testCoverageEnabled true
        }
    }
}

At this point, you should be able to run gradle connectedAndroidTest and view an html and xml report in the above mentioned directory.



Basic configuration

In order to get started, go to coveralls.io, login with your GitHub account and authorize Coveralls to access your repositories.



Next, we&amp;#39;ll need to configure your build.gradle files to upload the coverage reports to Coveralls after each successful CI build. Therefore add a new classpath dependency to the root projects build.gradle file.
buildscript {
    ...

    dependencies {
        ...
        classpath &amp;#39;org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.4.0&amp;#39;
    }
}

Then we can apply the coveralls plugin, point it to the coverage reports directory and ensure it only runs on CI builds by adding the following to your main module&amp;#39;s build.gradle file:
apply plugin: &amp;#39;com.github.kt3k.coveralls&amp;#39;
coveralls {
    jacocoReportPath = &amp;quot;${buildDir}/reports/coverage/debug/report.xml&amp;quot;
}

tasks.coveralls {
    dependsOn &amp;#39;connectedAndroidTest&amp;#39;
    onlyIf { System.env.&amp;#39;CI&amp;#39; }
}

Note that we also added a dependency on the connectedAndroidTest task as that is the one that will actually generate the code coverage report.

Let&amp;#39;s now change the build task in the travis.yml so it runs the coveralls task after every build. While not strictly necessary to still define the connectedAndroidTest task, I prefer to do so as it makes it more explicit what Gradle will exactly be building.
script:
  ...
  - ./gradlew connectedAndroidTest coveralls

Next we need to activate our GitHub repository in coveralls, so it picks up the output from the Gradle plugin. This can easily be done by clicking add repos on coveralls.io and flipping the switch on your repository.



This will result in the project being added to your dashboard without any builds.



Simply trigger a Travis build by pushing some changes to start seeing code coverage results online.

Finally you can easily add a badge to your repository by clicking the Badge urls button from the green banner in the detail view.



Congratulations you know have attractive code coverage reports for your repository!

Wrap-up

Adding Travis CI and Coveralls code coverage to your project is fairly straightforward once you know what works and especially what doesn&amp;#39;t work. Hopefully this blogpost was able to remove a lot of those frustrating barriers of entry.

A basic example project with everything in this blogpost integrated is available on GitHub. But in case you&amp;#39;re interested in a real life example, have a look at my Android library LandscapeVideoCamera, which actually has decent code coverage statistics.

 

As always you can reach me @molsjeroen on twitter, or leave a comment below!
</content>
 </entry>
 
 <entry>
   <title>Getting the most out of Artifactory</title>
   <link href="http://jeroenmols.com/blog/2015/08/13/artifactory2/"/>
   <updated>2015-08-13T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2015/08/13/artifactory2</id>
   <content type="html">My previous blog post described how to set up your own private Maven repository with Artifactory in 30 minutes. This second and final part will make things more interesting and take your setup to the next level.

You will learn how to:


handle library projects with dependencies
securely provide username and password
work with snapshot and release builds
configure custom repositories
manage user access


All source code is available on Github as usual.

Note that the material presented here can quite easily be extended to be applicable beyond Android.

Library projects with dependencies

Imagine if your Android library project itself has dependencies. Then the application using the library wouldn&amp;#39;t be able to run unless it provides all dependencies the library requires.

To better understand this, consider the new AwesomeAdvancedLibrary which makes use of Guava to awesomize a String. The application using this library should be agnostic of this dependency. Hence we do not want to define two dependencies:
dependencies {
    compile &amp;#39;com.jeroenmols.awesomeadvancedlibrary:awesomeadvancedlibrary:1.0.0&amp;#39;
    compile &amp;#39;com.google.guava:guava:18.0&amp;#39;
}

Instead one compile dependency should suffice to use the library.


Important note on including dependencies

You can skip this if you want, just some extra context

Including dependencies in your library is not always a good idea, because this can lead to a dependency conflict while integrating. I only choose Guava to keep things simple, but it is actually a very bad example as it is a utility library. This means it&amp;#39;s quite likely that the app also needs it.

A better example would be a universal analytics library offering a universal API to track analytics and redirecting all calls internally to one or more analytics providers. Here packaging dependencies makes sense, because the app never needs to talk to the dependency directly. It also hides implementation details, so the app doesn&amp;#39;t need to be modified when switching to a new provider.


Imagine if we would simply resort to the buildscript we had in my previous blogpost. At compile time the Guava dependency will not be included, because the would make the library unnecessarily large. Instead, the compiler will tell the library: &amp;quot;don&amp;#39;t worry about this dependency, the app will provide it for you.&amp;quot;

The app on the other hand wouldn&amp;#39;t have a clue which dependencies the library actually needs (how would it?) and hence the app will compile just fine. However, after starting the app and trying to access the library, the app would crash at runtime:
08-09 20:49:46.096  28892-28892/? E/AndroidRuntimeÔπï FATAL EXCEPTION: main
Process: com.jeroenmols.awesomeadvancedapplication, PID: 28892
java.lang.NoClassDefFoundError: Failed resolution of: Lcom/google/common/base/CharMatcher;
    at com.jeroenmols.awesomeadvancedlibrary.AwesomeConvertor.toAwesome(AwesomeConvertor.java:11)

To solve this, we need to ensure that the library pom.xml file  contains the right dependencies by manually adding the pom.withXml{} element to the publishing task:
publishing {
    publications {
        aar(MavenPublication) {
            groupId packageName
            version = libraryVersion
            artifactId project.getName()
            artifact(&amp;quot;$buildDir/outputs/aar/${project.getName()}-release.aar&amp;quot;)

            pom.withXml {
                def dependencies = asNode().appendNode(&amp;#39;dependencies&amp;#39;)
                configurations.getByName(&amp;quot;_releaseCompile&amp;quot;).getResolvedConfiguration().getFirstLevelModuleDependencies().each {
                    def dependency = dependencies.appendNode(&amp;#39;dependency&amp;#39;)
                    dependency.appendNode(&amp;#39;groupId&amp;#39;, it.moduleGroup)
                    dependency.appendNode(&amp;#39;artifactId&amp;#39;, it.moduleName)
                    dependency.appendNode(&amp;#39;version&amp;#39;, it.moduleVersion)
                }
            }
        }
    }
}

Note that while you can similarly add other repositories in this way to the pom.xml, Gradle itself won&amp;#39;t look for repositories in that file. Therefore if you use libraries from 3rd party repositories, you still need to add those repositories to the build.gradle of your app.

Securely provide username and password

Obviously we do not want to store a plain text username and password in any file that we check in to our version control system. So to make sure we hide those, create a gradle.properties file in the root of your project and add the following content:
artifactory_username=admin
artifactory_password=password

Then in your build.gradle file, refer to the properties like this:
username = artifactory_username
password = artifactory_password

We have now obfuscated the password, so it is no longer in the build.gradle file, but people can still find it in the gradle.properties file under version control. To prevent this, you must do one of the following:


Don&amp;#39;t add gradle.properties to your version control system. (add it to your .gitignore file instead)
Move the gradle.properties to the base ~/.gradle folder on your hard drive. I personally recommend this approach as you can never accidentally check in your username and password.


Working with Snapshot and Release builds

While the Artifactory Gradle plugin doesn&amp;#39;t have support for snapshot/release builds out of the box, it is easy to add this functionality by relying on the artifact version:


For release builds: use symantic versioning e.g. 1.0.0
For Snapshot builds: use symantic versioning with -SNAPSHOT suffix e.g. 1.0.0-SNAPSHOT


Now you can direct each one to a different Artifactory repository by changing the repository key as follows:
repoKey = libraryVersion.endsWith(&amp;#39;SNAPSHOT&amp;#39;) ? &amp;#39;libs-snapshot-local&amp;#39; : &amp;#39;libs-release-local&amp;#39;

On the application side you need to add two different Maven urls so you can refer to artifacts in both repositories.
allprojects {
    repositories {
      maven { url &amp;quot;http://localhost:8081/artifactory/libs-release-local&amp;quot; }
      maven { url &amp;quot;http://localhost:8081/artifactory/libs-snapshot-local&amp;quot; }
    }
}

Referencing artifacts is exactly the same as before, just don&amp;#39;t forget to add the -SNAPSHOT suffix for snapshot artifacts.

Alternatively we can also create a virtual repository in Artifactory which wraps around both repositories. This way the app only requires one URL, but does create a dependency on the existing Artifactory setup.


Login to Artifactory and go to admin &amp;gt; repositories &amp;gt; virtual

Create a new virtual maven repository which contains both libs-release-local and libs-snapshot-local

In the top level build.gradle of your application, replace the two previous URLS by the following:

  allprojects {
      repositories {
        maven { url &amp;quot;http://localhost:8081/artifactory/libs-local&amp;quot; }
      }
  }

User access management

Currently everyone can both read and write to all your repositories. This is not a good idea, especially if your server is also connected to the internet. Therefore we are going to set up two different users: one to deploy artifacts and one to consume artifacts.

In order to do so, go to artifactory and login as admin. Now navigate to admin &amp;gt; security &amp;gt; general and make the following changes:


set Allow Anonymous Access to false -&amp;gt; ensures only known Artifactory users can consume artifacts
set Password Encryption Policy to REQUIRED -&amp;gt; ensures we don&amp;#39;t have to hardcode a plain text password in our build.gradle.
press the encrypt button in the Password Encyption section -&amp;gt; encrypts all passwords


If the app now tries to consume an artifact, it will get a 401 error: unauthorized. You can verify this yourself by clearing the gradle cache (to force a dependency download):
gradle clean --refresh-dependencies

Next, go to the Users pane and add two new user: consumer and deployer. Make sure not to add them to any group.





Note that you probably also want to change your admin password at this stage. ;)

Now go to the Permissions pane and add a new Consume Libraries permission. Set the Selected repositories to include the snapshot and release repository, and in the Users tab add the consumer user with read permissions.





Add a second permission: Deploy Libraries with the snapshot and release repository included. Here give the deployer user Deploy/Cache permission but not Delete/Overwrite as you never want to override an existing artifact!





All we need to do now is modify the Library and Application to make use of these new users. This is easy for the Library as you can simply replace the admin user with the deploy user in the gradle.properties file.

For the Application we will need to provide credentials to access the Maven repository. Here we will hard code the username and password in the top level build.gradle file because team members should be able to checkout and build the code without extra configuration.

Therefore we will take some extra security precautions:


Use a user with read access to only a small subset of our repositories: deploy.
Check the code into a private repository, so the hardcoded password is protected by repository password.
Use the encrypted version of the password instead of the plain text version:


Login to artifactory as the consumer user
Navigate to the user settings in the top right corner
Unlock your profile with your password
Copy the API key





Now add the user authentication to the top level build.gradle file:
allprojects {
    repositories {
        jcenter()
        // NOTE: configure your virtual repository and user in artifactory to make this work
        maven {
            url &amp;quot;http://localhost:8081/artifactory/libs-local&amp;quot;
            credentials {
                username &amp;#39;consumer&amp;#39;
                password &amp;#39;APA52uxnRkmxeRXmJqd7haMpwgg&amp;#39;
            }
        }
    }
}

And we are all set with authenticated access to our repositories.

Wrap-up

That&amp;#39;s a wrap to my two part blogpost about Artifactory! We made our previous repository a lot more secure, added support for dependencies and can now differentiate between release and snapshot artifacts.

No more excuses not to write reusable code!

Feel free to leave a comment and don&amp;#39;t forget to check the full source code on Github.
</content>
 </entry>
 
 <entry>
   <title>A private Maven repository for Android in 30 min</title>
   <link href="http://jeroenmols.com/blog/2015/08/06/artifactory/"/>
   <updated>2015-08-06T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2015/08/06/artifactory</id>
   <content type="html">Setting up your own Maven repository and uploading artifacts to it is quite a daunting task. As I went through this experience myself recently, I want to help others in setting up their own Maven repository via Artifactory and automate uploading artifacts using Gradle.

In less than 30 minutes you will have a fully operational private Maven repository and have configured your Gradle buildscripts to upload your Android library artifacts.

Note that the material presented here can quite easily be extended to be applicable in a broader scope beyond Android.

Setting up a Repository Manager

First of all we need to make sure we have an actual Maven repository to upload our artifacts to. According to Maven you should use a repository manager to do that:


Best Practice - Using a Repository Manager

A repository manager is a dedicated server application designed to manage repositories of binary components. The usage of a repository manager is considered an essential best practice for any significant usage of Maven.


Why Artifactory?

While there are some options available to choose from, I personally selected Artifactory because:


Clear and attractive UI
Super fast configuration
Gradle plugin
User access control
Free and open source




For more information have a look at the alternatives, checkout this feature comparison matrix or review all of the Artifactory features.

Verify you have Java SDK 8

Before you get started, make sure that you have Java SDK 8 installed, or otherwise Artifactory won&amp;#39;t start. You can easily verify your Java version with java -version:
$ java -version
java version &amp;quot;1.8.0_51&amp;quot;
Java(TM) SE Runtime Environment (build 1.8.0_51-b16)
Java HotSpot(TM) 64-Bit Server VM (build 25.51-b03, mixed mode)

If it doesn&amp;#39;t output at least version 1.8.x, you should download and install a new Java SDK before you continue.

Note that the error you get if you don&amp;#39;t have Java 8 looks a bit cryptic:
Aug 05, 2015 9:29:31 AM org.apache.catalina.core.StandardContext startInternal
SEVERE: One or more listeners failed to start. Full details will be found in the appropriate container log file

Install Artifactory

Thankfully this is incredibly easy to do. Just download the latest version of Artifactory, unpack the archive and run the artifactory executable for your platform.



You can easily verify your installation and start experimenting with its features by navigating to http://localhost:8081/artifactory/. For now, don&amp;#39;t worry about all of the settings, we will configure what we need later on.

Configuring Gradle to upload Android artifacts

Let&amp;#39;s upload a very simple archive by configuring a new Gradle task for our Android library project.

In your top level build.gradle file, add a reference to the repository of the Artifactory Gradle plugin:
buildscript {
    dependencies {
        classpath &amp;quot;org.jfrog.buildinfo:build-info-extractor-gradle:3.1.1&amp;quot;
    }
}

Next in your library we will need to apply two new plugins: one to prepare the Maven artifacts maven-publish and one to upload the archives to Artifactory com.jfrog.artifactory:
apply plugin: &amp;#39;com.jfrog.artifactory&amp;#39;
apply plugin: &amp;#39;maven-publish&amp;#39;

Every Maven artifact is identified by three different parameters:


artifactId: the name of your library
groupId: usually the package name of your library
version: identifies different releases of the same artifact


For the last two, we will explicitly define a variable in the build.gradle file.
def packageName = &amp;#39;com.jeroenmols.awesomelibrary&amp;#39;
def libraryVersion = &amp;#39;1.0.0&amp;#39;

The artifactId however needs to match the output filename of the assembleRelease task. Therefore we either have to rename the library module or explicitly specify the output filename. I personally prefer the first approach, which allows to get artifactId in the following way:
project.getName() // the ArtifactId

Now we need to configure the maven-publish plugin so that it knows which artifacts to publish to Artifactory. For our purpose we will refer to the ***-release.aar file, generated by the assembleRelease task. Note that we can predict the name by taking the name of the Library project:
publishing {
    publications {
        aar(MavenPublication) {
            groupId packageName
            version = libraryVersion
            artifactId project.getName()

            // Tell maven to prepare the generated &amp;quot;*.aar&amp;quot; file for publishing
            artifact(&amp;quot;$buildDir/outputs/aar/${project.getName()}-release.aar&amp;quot;)
      }
    }
}

Finally we need to configure the com.jfrog.artifactory plugin so it knows which repository to publish the artifacts to. For simplicity we will upload the artifact to the locally running Artifactory instance (http://localhost:8081/artifactory) and place it in the default libs-release-local repository. Note that the username admin and password password are hardcoded in this example, but we will provide a better solution for that later.
artifactory {
    contextUrl = &amp;#39;http://localhost:8081/artifactory&amp;#39;
    publish {
        repository {
            // The Artifactory repository key to publish to
            repoKey = &amp;#39;libs-release-local&amp;#39;

            username = &amp;quot;admin&amp;quot;
            password = &amp;quot;password&amp;quot;
        }
        defaults {
            // Tell the Artifactory Plugin which artifacts should be published to Artifactory.
            publications(&amp;#39;aar&amp;#39;)
            publishArtifacts = true

            // Properties to be attached to the published artifacts.
            properties = [&amp;#39;qa.level&amp;#39;: &amp;#39;basic&amp;#39;, &amp;#39;dev.team&amp;#39;: &amp;#39;core&amp;#39;]
            // Publish generated POM files to Artifactory (true by default)
            publishPom = true
        }
    }
}

Deploying artifacts

Now that our Gradle buildscripts are properly configured we can easily publish artifacts to Artifactory by running the following command:
gradle assembleRelease artifactoryPublish

Notice how we first invoke assembleRelease before we invoke the actual artifactoryPublish task, because of the way we defined the artifacts to publish in the previous section.

You can very easily verify that the upload was successful by navigating to localhost:8081 and signing in with the default admin credentials.



Using the artifacts

To make use of the published artifacts in another project we have to add our Artifactory repository to the list of Maven repositories in your top level build.gradle file:
allprojects {
    repositories {
        maven { url &amp;quot;http://localhost:8081/artifactory/libs-release-local&amp;quot; }
    }
}

After we can simply add the artifact as a dependency in the build.gradle file of our main project:
dependencies {
    compile &amp;#39;com.jeroenmols.awesomelibrary:1.0.0&amp;#39;
}

Wrap-up

Congratulations! You now have a fully working Maven repository manager with a Gradle script to generate and upload your artifacts.

In the next blog post I will zoom in on more advanced topics like:


Library projects with dependencies
Configuring your own repositories
User access management and rights
Removing hardcoded username and password from build.gradle


I have also uploaded a complete example on GitHub for your reference.
</content>
 </entry>
 
 <entry>
   <title>How I created my blog</title>
   <link href="http://jeroenmols.com/blog/2015/04/25/blog-creation/"/>
   <updated>2015-04-25T00:00:00+02:00</updated>
   <id>http://jeroenmols.com/blog/2015/04/25/blog-creation</id>
   <content type="html">Preface

For quite some months, I&amp;#39;ve been planning to create a website and start blogging about the things I&amp;#39;m passionate about. Last week, I finally decided to setup a portfolio and blog using GitHub pages and Jekyll.

Since I&amp;#39;m an Android and not a web developer, the first blogging subject wasn&amp;#39;t hard to find: challenges I came across in setting up this website and blog.


Disclaimer: Eventually I had to use a workaround - that&amp;#39;s why I don&amp;#39;t build websites professionally - but I strongly believe in a Just do It mentality and then learn/improve as you go.


Why Jekyll

Keeping it simple, I only had few requirements for my blog:


Responsive website
Easy to setup and maintain
No lock-in: able to migrate to other platforms
Support for pagination and comments


First thing I learned was the difference between a static (e.g. Jekyll) and dynamic website (e.g. Wordpress) via a great presentation by @plusjade.

The main advantage of static websites is their loading speed because all pages are generated before they are served. Installing the generator on your local machine is simple, making it easy to test your site before deploying online. Posts are written in Markdown, so no HTML clutter nor extra tools needed. Just a text generator and Git to conveniently version all changes.


Protip: One of my colleagues @inferis even gets spelling corrections via Pull request!


As GitHub pages natively supports Jekyll, I didn&amp;#39;t really spent much time on choosing which static site generator to use.

Setting up

Installing Jekyll was really a breeze, I just had to run gem install Jekyll and then I could build my website using jekyll build or test it locally using jekyll serve.


Note: both commands will generate your website in the _site folder, which you shouldn&amp;#39;t add to version control!


Instead of making a new Jekyll site, I decided to fork two existing themes:


Hyde: a clean two-column theme for my Blog
Freelancer: to have a cool portfolio


Both themes offer quite some predefined customization options via the _config.yml file, but for advanced theming you can also directly edit the CSS files.

Merging two Jekyll themes

Where I originally only wanted to have a blog, the Freelancer theme was just too cool to ignore. Consequently merging two themes was one of the first things I had to do.

It seemed most convenient to have my portfolio under my main url and to include my blog under a subfolder (i.e. jeroenmols.github.io/blog).

To do this I merged the blog theme into the portfolio (main) theme:


Add a subfolder blog/ with the index.html of my blog.
Move all my portfolio posts and blog posts into separate folders:


all portfolio posts went into portfolio/_posts
all blog posts went into blog/_posts


This allows to easily loop through all portfolio or blog posts separately:
- {% for post in site.categories.portfolio %}
- {% for post in site.categories.blog %}
Move all files in _layouts and _includes from my blog into the corresponding folders of my portfolio theme.


Optionally you can move files into subfolders to keep things clean (_includes/blog), as long as you also update all references to these files. (in _layouts/blog.html I now refer to my includes as blog/&amp;lt;original name&amp;gt;)
Same holds true if you have naming conflicts (for instance two layouts with the same name), you can just rename one and update all references in all files using it.

Move all other folders and files into the root of the main theme
Merge the configurations from both _config.yml files


Again you can rename conflicting configurations (or merge duplicate ones) if you update all references.

Fix all references to not found images/css/... files in the blog theme. This is necessary because the original theme was assuming to run in the root directory, and now we moved it to a subdirectory blog/.


I found that the best way to do this is to run jekyll build and have a look at the generated output in the _site directory. From this you can learn what&amp;#39;s wrong and fix it.



After this I could run Jekyll serve and everything worked flawlessly!

...

Wait...

...

Why are my portfolio posts also showing up in my blog?

...

Damn you Jekyll!

Turns out Jekyll does not support paginating categories and hence it will lump all posts it finds together, in my case both portfolio (unwanted) and blog (wanted). Even more, there is no plugin to add this functionality either! Pretty weird, and a huge limitation if you ask me.

So I did what every self-respecting programmer would do: pray to the Stackoverflow and GitHub gods. And my prayers where answered by a code snippet of benxtan, which I found in an issue tracker of a very old Jekyll pagination plugin. To enable this plugin, simply create a _plugins folder and copy the code snippet into a category_pagination.rb file.


Note: the former plugin was no longer working, because it was referring to classes that were renamed/moved classes in newer Jekyll versions.


GitHub and Jekyll plugins

My new shiny portfolio and blog were working locally, but when I pushed it to GitHub, the pagination again included both blog and portfolio posts. Turns out that GitHub doesn&amp;#39;t allow you to run custom Jekyll plugins except for a few that they have whitelisted.


Plugins on GitHub Pages

GitHub Pages is powered by Jekyll. However, all Pages sites are generated using the --safe option to disable custom plugins for security reasons. Unfortunately, this means your plugins won‚Äôt work if you‚Äôre deploying to GitHub Pages.


At this point, I am/was completely stuck, because even if Jekyll would add support for category pagination, I would still need to wait for GitHub to update their Jekyll version.

Only option remaining was to directly push the generated _site directory into my repository and to disable the Jekyll generator on GitHub pages.


Note that this is a really suboptimal solution, because this effectively means pushing a high amount of auto-generated files to your repo, frequently. So if anyone has a better suggestion to solve the pagination issue, please let me know!


To make this work, there are a couple of things you need to do:


Disable Jekyll on GitHub pages by pushing an empty file with name .nojekyll to the root of your repo
Move all auto generated content from the _site folder into the root of your repository, so that its index.html is displayed when someone browses to your main page.


This actually by itself imposes a new problem, namely where to put your Jekyll source code? I solved this by:


move all source files to a subfolder jekyll-source in my main repository
generating all static pages into jekyll-source/_site using jekyll build
removing all files and folders from my root directory, except for the jekyll-source directory
copying the entire content of jekyll-source/_site into my root folder


I know this is not a great solution, but it gets the job done, and I was able to automate all of this in a release script that you can run by calling .release from the jekyll-source folder.


Note: I also considered two other options:


Use a CNAME file to redirect my main url into a subfolder. This does not work, as the CNAME file can only be used for top-level domains.
Use a placeholder index.html which redirect the main url into a subfolder.


I didn&amp;#39;t use any of those mechanisms as that would unnecessarily complicate my website url.


Protips

If you really want to make your site look spectacular:


Site icon: add the following to the head of your index.html page:
&amp;lt;link rel=&amp;quot;favicon-144-precomposed&amp;quot; sizes=&amp;quot;144x144&amp;quot; href=&amp;quot;&amp;lt;link_to_your_icon&amp;gt;&amp;quot;&amp;gt;
Site toolbar/status bar color on Android: add the following to the head of your index.html page: &amp;lt;meta name=&amp;quot;theme-color&amp;quot; content=&amp;quot;&amp;lt;your_color_hex&amp;gt;&amp;quot;&amp;gt;


Conclusion

I&amp;#39;m glad that I finally got my portfolio and blog up and running. My current solution might not be the best one in the world, but it is automated, maintainable and I can easily add blog posts in the future. Don&amp;#39;t hesitate to look at my GitHub repo for the full source code. Hopefully the code and my post can help others to setup the same in the future.

Would I use Jekyll again if I would start over? Probably yes.

The only real limitation I ran into was due to the paginator combining the posts from both my portfolio and blog. This caused me to disable Jekyll completely and push the generated site directly to GitHub pages. While this really sucked, using another static site generator would also have forced me to do this (because GitHub only supports Jekyll). Furthermore combining two themes is already quite advanced, and if you stick to just one theme Jekyll is actually very convenient to use.
</content>
 </entry>
 

</feed>
